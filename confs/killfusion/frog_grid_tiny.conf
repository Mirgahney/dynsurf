general {
    base_exp_dir = ./exp/CASE_NAME/result
    recording = [
        ./,
        ./models,
        ./models/LieAlgebra,
    ]
}

dataset {
    data_dir = /mnt/data/KillingFusion/kfusion_frog #/jmain02/home/J2AD021/dxt03/mmm91-dxt03/data/KillingFusion/kfusion_frog # ./datasets/CASE_NAME/
    render_cameras_name = cameras_sphere.npz
    object_cameras_name = cameras_sphere.npz
    # Camera
    is_monocular = True # if the camera setting is monocular, set True

    # Depth
    use_depth = True
    # scale factor of depth
    # e.g. a pixel value of 1000 in the depth image corresponds to a distance of 1 meter from the camera.
    depth_scale = 1000.
    # Camera
    camera_trainable = True
    # Train skip
    trainskip = 1 #2 #10
    max_length = 200
}

train {
    learning_rate = 5e-4
    learning_rate_alpha = 0.05
    end_iter = 20000 #120000 #60000 #120000
    batch_size = 1024 # 2048
    validate_resolution_level = 4
    warm_up_end = 800 #5000
    anneal_end = 0
    igr_weight = 0.5
    mask_weight = 0.5
    # Depth
    geo_weight = 5.0
    angle_weight = 0.0 #0.5
    # our losses
    sdf_weight = 0.5
    fs_weight = 2.0
    surf_sdf = 0.0
    # Deform
    use_deform = True
    use_topo = True
    use_bijective = True #False #True
    use_global_rigid = False
    use_app = True
    use_pts = True
    bij_type = rnvp #ndr
    # Anneal. Coarse-to-Fine Optimization.
    max_pe_iter = 70000

    save_freq = 10000
    val_freq = 10000
    val_mesh_freq = 10000
    report_freq = 10000

    validate_idx = -1 # index of validation

    truncation = 0.08  # 0.08
    back_truncation = 0.05 #0.5

    # image sampling strategy
    sample_sequential = False #True
}

test {
    test_batch_size = 3072
}

model {
    # Deform
    deform_network {
        d_feature = 64
        d_in = 3
        d_out_1 = 1 # t
        d_out_2 = 3 # (r,t) in 2d
        n_blocks = 3
        d_hidden = 128
        n_layers = 1
        skip_in = []
        multires = 6
        weight_norm = True
    }

    # Deform
    topo_network {
        d_feature = 64
        d_in = 3
        d_out = 2
        d_hidden = 64
        n_layers = 7
        skip_in = [5]
        multires = 6
        bias = 0.0
        weight_norm = True
        use_topo = True
    }

    feature_grid {
    feat_dims = [14, 8, 4] #[10, 4, 4]
    res = 124 #124 #149
    rgb_dim = 6
    }
    sdf_network {
        d_out = 257
        d_in_1 = 20 #12 #3
        d_in_2 = 2 # use_topo dim
        d_hidden = 32 #256
        n_layers = 2 #8
        skip_in = [] #[4]
        multires = 0 #6
        multires_topo = 1 # use_topo
        bias = 0.5
        scale = 1.0
        geometric_init = True
        weight_norm = False #True
    }

    tiny_sdf_network {
        d_in_1 = 20 #12 #3
        d_in_2 = 2 # use_topo dim
        d_out = 1
        multires = 2

        #tinycudnn
        tiny_config {
            encoding {
		        otype = OneBlob
		        n_bins= 4 #64

		        #otype = HashGrid
		        #n_levels = 4 #16
		        #n_features_per_level = 2
		        #log2_hashmap_size = 3 #15
		        #base_resolution = 4 #16
		        #per_level_scale = 1.5
	        }

	        tiny_network {
		        otype = FullyFusedMLP
		        activation= ReLU
		        output_activation = None
		        n_neurons = 32 #64
		        n_hidden_layers = 2
	        }
	    }
    }

    variance_network {
        init_val = 0.3
    }

    # Deform
    appearance_rendering_network {
        d_feature = 6 #256
        d_global_feature = 64
        mode = idr
        d_in = 9
        d_out = 3
        d_hidden = 64 #256
        n_layers = 2 #4
        weight_norm = True
        multires_view = 4
        squeeze_out = True
    }

    rendering_network {
        d_global_feature = 64
        mode = idr
        d_in = 15 #rgb_dim + 9 (noramls+pts_can+view_dir)
        d_out = 3
        multires_view = 0 #4
        squeeze_out = True

        #tinycudnn
        tiny_config {
            encoding {
		        otype = OneBlob
		        n_bins= 64
	        }


	        tiny_network {
		        otype = FullyFusedMLP
		        activation= ReLU
		        output_activation = None
		        n_neurons = 32 #64
		        n_hidden_layers = 2
	        }
	    }
    }

    neus_renderer {
        begin_n_samples = 64
        end_n_samples = 16
        important_begin_iter = 8000 #40000
        n_importance = 64
        up_sample_steps = 4
        perturb = 1.0
    }
}
